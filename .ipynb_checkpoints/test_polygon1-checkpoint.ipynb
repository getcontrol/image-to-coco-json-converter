{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "wrong-compound",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --dataset DATASET\n",
      "ipykernel_launcher.py: error: the following arguments are required: --dataset\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import json\n",
    "import numpy as np                                 # (pip install numpy)\n",
    "from PIL import Image # (pip install Pillow)\n",
    "from skimage import measure                        # (pip install scikit-image)\n",
    "from shapely.geometry import Polygon, MultiPolygon # (pip install Shapely)\n",
    "\n",
    "SPLIT_RATIO = 0.9\n",
    "\n",
    "def create_sub_masks(mask_image):\n",
    "    width, height = mask_image.size\n",
    "    # Initialize a dictionary of sub-masks indexed by RGB colors\n",
    "    sub_masks = {}\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            # Get the RGB values of the pixel\n",
    "            pixel = mask_image.getpixel((x,y))\n",
    "            \n",
    "            # If the pixel is not black...\n",
    "            if pixel != 0:\n",
    "                # Check to see if we've created a sub-mask...\n",
    "                pixel_str = str(pixel)\n",
    "                sub_mask = sub_masks.get(pixel_str)\n",
    "                if sub_mask is None:\n",
    "                   # Create a sub-mask (one bit per pixel) and add to the dictionary\n",
    "                    # Note: we add 1 pixel of padding in each direction\n",
    "                    # because the contours module doesn't handle cases\n",
    "                    # where pixels bleed to the edge of the image\n",
    "                    sub_masks[pixel_str] = Image.new('1', (width+2, height+2))\n",
    "\n",
    "                # Set the pixel value to 1 (default is 0), accounting for padding\n",
    "                sub_masks[pixel_str].putpixel((x+1, y+1), 1)\n",
    "\n",
    "    return sub_masks\n",
    "\n",
    "def create_sub_mask_annotation(sub_mask, image_id, category_id, annotation_id, is_crowd):\n",
    "    # Find contours (boundary lines) around each sub-mask\n",
    "    # Note: there could be multiple contours if the object\n",
    "    # is partially occluded. (E.g. an elephant behind a tree)\n",
    "    contours = measure.find_contours(sub_mask, 0.5, positive_orientation='low')\n",
    "\n",
    "    segmentations = []\n",
    "    polygons = []\n",
    "    for contour in contours:\n",
    "        # Flip from (row, col) representation to (x, y)\n",
    "        # and subtract the padding pixel\n",
    "        for i in range(len(contour)):\n",
    "            row, col = contour[i]\n",
    "            contour[i] = (col - 1, row - 1)\n",
    "\n",
    "        # Make a polygon and simplify it\n",
    "        poly = Polygon(contour)\n",
    "        poly = poly.simplify(1.0, preserve_topology=False)\n",
    "        polygons.append(poly)\n",
    "        segmentation = np.array(poly.exterior.coords).ravel().tolist()\n",
    "        segmentations.append(segmentation)\n",
    "\n",
    "    # Combine the polygons to calculate the bounding box and area\n",
    "    multi_poly = MultiPolygon(polygons)\n",
    "    x, y, max_x, max_y = multi_poly.bounds\n",
    "    width = max_x - x\n",
    "    height = max_y - y\n",
    "    bbox = (x, y, width, height)\n",
    "    area = multi_poly.area\n",
    "\n",
    "    annotation = {\n",
    "        'segmentation': segmentations,\n",
    "        'iscrowd': is_crowd,\n",
    "        'image_id': image_id,\n",
    "        'category_id': category_id,\n",
    "        'id': annotation_id,\n",
    "        'bbox': bbox,\n",
    "        'area': area\n",
    "    }\n",
    "\n",
    "    return annotation\n",
    "\n",
    "def thread_function(obj):\n",
    "    global train_img_id, valid_img_id\n",
    "    global train_ann_id, valid_ann_id\n",
    "\n",
    "    id_name, dir_name = obj[0], obj[1]\n",
    "    path_to_mask_dir = \"dataset_test/masks\"\n",
    "    mask_image_names = [os.path.join(path_to_mask_dir, fn) for fn in os.listdir(path_to_mask_dir)]\n",
    "    split_id = int(len(mask_image_names)*SPLIT_RATIO)\n",
    "    train_image_names = mask_image_names[:split_id]\n",
    "    valid_image_names = mask_image_names[split_id:]\n",
    "    print(\"working on dir: {}\".format(dir_name))\n",
    "    # For train images\n",
    "    for mask_fn in train_image_names:\n",
    "        mask_image = Image.open(mask_fn)\n",
    "        rgb_image_name = \"frames/frame_\" + os.path.basename(mask_fn).split(\"_\")[1]\n",
    "        rgb_image_name = os.path.splitext(rgb_image_name)[0] + \".jpg\"\n",
    "        train_images_info.append({\"file_name\": os.path.join(os.path.dirname(os.path.abspath(path_to_mask_dir)),\n",
    "                                                            rgb_image_name), \n",
    "                                  \"height\": mask_image.size[1],\n",
    "                                  \"width\": mask_image.size[0],\n",
    "                                  \"id\": train_img_id})\n",
    "        sub_masks = create_sub_masks(mask_image)\n",
    "        for color, sub_mask in sub_masks.items():\n",
    "            category_id = category_ids[id_name+1][color] #(category_id==(id_name+1))\n",
    "            annotation = create_sub_mask_annotation(sub_mask, train_img_id, category_id, train_ann_id, is_crowd)\n",
    "            train_annotations.append(annotation)\n",
    "            train_ann_id += 1\n",
    "        train_img_id +=1\n",
    "    # For validation images\n",
    "    for mask_fn in valid_image_names:\n",
    "        mask_image = Image.open(mask_fn)\n",
    "        rgb_image_name = \"frames/frame_\" + os.path.basename(mask_fn).split(\"_\")[1]\n",
    "        rgb_image_name = os.path.splitext(rgb_image_name)[0] + \".jpg\"\n",
    "        valid_images_info.append({\"file_name\": os.path.join(os.path.dirname(os.path.abspath(path_to_mask_dir)),\n",
    "                                                            rgb_image_name), \n",
    "                                  \"height\": mask_image.size[1],\n",
    "                                  \"width\": mask_image.size[0],\n",
    "                                  \"id\": valid_img_id})\n",
    "        sub_masks = create_sub_masks(mask_image)\n",
    "        for color, sub_mask in sub_masks.items():\n",
    "            category_id = category_ids[id_name+1][color] #(category_id==(id_name+1))\n",
    "            annotation = create_sub_mask_annotation(sub_mask, valid_img_id, category_id, valid_ann_id, is_crowd)\n",
    "            valid_annotations.append(annotation)\n",
    "            valid_ann_id += 1\n",
    "        valid_img_id +=1\n",
    "    return \n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # get command line arguments\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"--dataset\", required=True, help='path to root dir of labeled dataset')\n",
    "    opt = ap.parse_args()\n",
    "\n",
    "    #list_of_dirs = [dirname for dirname in os.listdir(opt.dataset) if dirname.split('_')[-1]!='gt']\n",
    "    list_of_dirs = [\"dewalt_tool\", \"facom_wrench\", \"hitachi_screw_gun\",\n",
    "                    \"cupnoodle\", \"lipton\", \"mtrainier\", \"oolong\",\n",
    "                    \"_mustard_bottle\", \"_potted_meat_can\", \"_bleach_cleanser\", \"_power_drill\"]\n",
    "\n",
    "    # Define which colors match which categories in the images\n",
    "    category_ids = {i: {'255': i,} for i in range(1,12)}\n",
    "\n",
    "    is_crowd = 0\n",
    "\n",
    "    # These ids will be automatically increased as we go\n",
    "    train_ann_id, valid_ann_id = 1, 1\n",
    "    train_img_id, valid_img_id = 1, 1\n",
    "\n",
    "    # Create the annotations\n",
    "    train_annotations, valid_annotations = [], []\n",
    "    train_images_info, valid_images_info = [], []\n",
    "\n",
    "    for object_id, object_dir in enumerate(list_of_dirs):\n",
    "        thread_function([object_id, object_dir])\n",
    "\n",
    "\n",
    "    output = {\"images\": train_images_info, \"annotations\": train_annotations}\n",
    "    print(\"Writing to file train_labels.json...\" )\n",
    "    with open(\"train_labels.json\", \"w\") as outfile:\n",
    "        json.dump(output, outfile)\n",
    "        print(\"Done.\")\n",
    "\n",
    "    output = {\"images\": valid_images_info, \"annotations\": valid_annotations}\n",
    "    print(\"Writing to file valid_labels.json...\" )\n",
    "    with open(\"valid_labels.json\", \"w\") as outfile:\n",
    "        json.dump(output, outfile)\n",
    "        print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quick-wesley",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
